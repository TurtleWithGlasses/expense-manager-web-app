# Production Deployment Checklist - Performance Optimization

## üìã Pre-Deployment Checklist

### ‚úÖ Code Review
- [x] Database indexes added to Entry model
- [x] Alembic migration created and tested locally
- [x] All changes committed to git
- [x] No hardcoded secrets or sensitive data
- [x] Migration is reversible (downgrade implemented)

### ‚úÖ Testing
- [x] Migration runs successfully in development (SQLite)
- [x] Indexes verified in local database
- [x] No breaking changes to application code
- [x] Zero application code changes required

### ‚úÖ Documentation
- [x] PERFORMANCE_IMPROVEMENTS.md created
- [x] PROJECT_ROADMAP.md updated
- [x] Migration includes descriptive comments

---

## üöÄ Deployment Steps

### Step 1: Push to Repository

```bash
# Verify all commits are ready
git log --oneline -5

# Push to GitHub
git push origin main
```

**Expected commits:**
1. `9aba214` - Add database indexes for performance optimization
2. `9bac864` - Update roadmap: Mark Phase 25 partially complete
3. `b7bb36a` - Add CORS configuration for mobile/API client support
4. `911a98e` - Add JWT token-based authentication for mobile/API clients
5. `7dac04b` - Update roadmap: Mark Phase 24 complete

---

### Step 2: Deploy to Railway (Automatic)

**Railway will automatically:**
1. Detect the new commit
2. Build the application
3. Run the startup migration check

**On startup, the app will:**
```python
# app/main.py startup event
command.upgrade(alembic_cfg, "head")  # Runs our migration
```

**Monitor deployment:**
1. Go to https://railway.app/project/your-project
2. Check deployment logs
3. Look for: `"Running upgrade 91bdbf9e0309 -> 9d7fd170f147, Add performance indexes to entries table"`

---

### Step 3: Verify Migration in Production

**Option A: Using Railway CLI**
```bash
# Connect to production database
railway connect postgres

# List indexes on entries table
\d entries

# Or using SQL
SELECT indexname, indexdef
FROM pg_indexes
WHERE tablename = 'entries';
```

**Expected indexes:**
```
ix_entries_user_id
ix_entries_date
ix_entries_type
ix_entries_category_id
ix_entries_user_date
```

**Option B: Using Python Script**
```bash
# SSH into Railway container or run locally with production DB
railway run python -c "
from app.db.engine import engine
from sqlalchemy import inspect
inspector = inspect(engine)
indexes = inspector.get_indexes('entries')
for idx in indexes:
    print(f\"‚úÖ {idx['name']}\")
"
```

---

### Step 4: Performance Monitoring

#### A. Check Query Performance

**Using PostgreSQL pg_stat_statements:**
```sql
-- Enable pg_stat_statements (if not already enabled)
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- Check slowest queries on entries table
SELECT
    query,
    calls,
    mean_exec_time,
    max_exec_time
FROM pg_stat_statements
WHERE query LIKE '%entries%'
ORDER BY mean_exec_time DESC
LIMIT 10;
```

#### B. Monitor Application Performance

**Check FastAPI logs:**
```bash
railway logs

# Look for request timing logs:
# "Request completed: GET /api/entries - 200 - 5ms"
```

#### C. Test API Endpoints

**Test dashboard endpoint:**
```bash
# Replace with your production URL and token
curl -X GET "https://www.yourbudgetpulse.online/api/dashboard/summary" \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  -w "\nTime: %{time_total}s\n"
```

**Expected response time:**
- Before indexes: 300-800ms
- After indexes: 10-50ms

---

### Step 5: Rollback Plan (If Needed)

**If something goes wrong:**

```bash
# Option 1: Rollback migration via Railway CLI
railway run alembic downgrade -1

# Option 2: Manual rollback via SQL
railway connect postgres

# Drop indexes manually
DROP INDEX ix_entries_user_date;
DROP INDEX ix_entries_category_id;
DROP INDEX ix_entries_type;
DROP INDEX ix_entries_date;
DROP INDEX ix_entries_user_id;
```

**Then redeploy previous commit:**
```bash
git revert HEAD~2  # Revert the last 2 commits
git push origin main
```

---

## üìä Post-Deployment Validation

### Performance Benchmarks to Check

| Metric | Before | Expected After | Test Command |
|--------|--------|----------------|--------------|
| Dashboard load | 300-800ms | <50ms | `curl -w "@curl-format.txt" /api/dashboard/summary` |
| Entry list query | 100-500ms | <10ms | `curl -w "@curl-format.txt" /api/entries?limit=10` |
| Category filter | 150-400ms | <10ms | `curl -w "@curl-format.txt" /api/entries?category_id=1` |

### Health Checks

1. **Application Health:**
   ```bash
   curl https://www.yourbudgetpulse.online/healthz
   # Expected: {"ok": true}
   ```

2. **Database Connection:**
   ```bash
   railway logs | grep "Database"
   # Should see: "Database already at latest migration (9d7fd170f147)"
   ```

3. **No Errors:**
   ```bash
   railway logs | grep -i error
   # Should see no new errors related to indexes
   ```

---

## üîç Monitoring Recommendations

### Short-term (First 24 hours)

- [ ] Monitor Railway deployment logs
- [ ] Check for any migration errors
- [ ] Verify indexes were created
- [ ] Test API endpoints manually
- [ ] Monitor for any user-reported issues

### Medium-term (First week)

- [ ] Monitor query performance metrics
- [ ] Check database size (indexes add storage)
- [ ] Verify no performance regressions
- [ ] Collect user feedback on performance

### Long-term (Ongoing)

- [ ] Set up APM (DataDog, New Relic, or Sentry)
- [ ] Configure alerts for slow queries (>100ms)
- [ ] Track database index usage
- [ ] Monitor disk space (indexes use ~5-10% more space)

---

## üìà Success Criteria

Deployment is successful if:

- ‚úÖ Migration completes without errors
- ‚úÖ All 5 indexes are created
- ‚úÖ Application starts successfully
- ‚úÖ No increase in error rate
- ‚úÖ API response times decrease
- ‚úÖ Users report faster page loads

---

## üö® Troubleshooting

### Issue: Migration fails with "index already exists"

**Cause:** Indexes were already created manually or by previous migration

**Solution:**
```sql
-- Check which indexes exist
\d entries

-- If needed, update migration to skip existing indexes
-- Or drop and recreate
```

### Issue: Slow queries persist

**Cause:** PostgreSQL query planner not using indexes

**Solution:**
```sql
-- Analyze table to update statistics
ANALYZE entries;

-- Force use of index (if needed)
SET enable_seqscan = OFF;
```

### Issue: High disk usage

**Cause:** Indexes require additional storage

**Solution:**
- Indexes typically use 5-10% of table size
- Monitor with: `SELECT pg_size_pretty(pg_total_relation_size('entries'));`
- This is normal and expected

---

## üìù Deployment Log Template

```
Date: [YYYY-MM-DD HH:MM]
Deployed by: [Your Name]
Environment: Production (Railway)

Changes:
- Added 5 database indexes to entries table
- Migration ID: 9d7fd170f147

Pre-deployment checks:
[x] Code reviewed
[x] Tests passed locally
[x] Migration tested in dev
[x] Documentation updated

Deployment steps:
[x] Pushed to GitHub (commit: 9aba214)
[x] Railway auto-deployed
[x] Migration ran successfully
[x] Indexes verified in production
[x] Performance tested

Results:
- Dashboard load time: 750ms ‚Üí 15ms (50x faster)
- Entry query time: 320ms ‚Üí 3ms (100x faster)
- No errors detected
- Users report faster performance

Status: ‚úÖ SUCCESS
```

---

## üéØ Next Steps After Deployment

1. **Monitor for 24-48 hours**
   - Watch for any performance regressions
   - Check error logs
   - Verify database health

2. **Gather Performance Data**
   - Collect actual before/after metrics
   - Document real-world improvements
   - Update PERFORMANCE_IMPROVEMENTS.md with production results

3. **Consider Future Optimizations**
   - Redis caching (if needed)
   - Background job queue (for reports)
   - Additional indexes (if specific slow queries identified)

4. **Communicate Success**
   - Update team on deployment
   - Share performance improvements
   - Document lessons learned

---

## üìû Rollback Contacts

**If issues arise:**
- Check Railway logs first
- Consult PERFORMANCE_IMPROVEMENTS.md
- Use rollback procedure above
- Document any issues for future reference

---

**Last Updated:** November 22, 2025
**Created By:** Claude Code
**Review Status:** Ready for Production ‚úÖ
